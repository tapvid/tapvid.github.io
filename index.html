<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="TAP-Vid: A Benchmark for Tracking Any Point in a Video">
  <meta name="keywords" content="TAP-Vid">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TAP-Vid: A Benchmark for Tracking Any Point in a Video</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://deepmind.com">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://deepmind-tapir.github.io/">
              TAPIR
            </a>
            <a class="navbar-item" href="https://robotap.github.io/">
              RoboTAP
            </a>
            <a class="navbar-item" href="https://deepmind-tapir.github.io/blogpost.html">
              TAPIR Blog Post
            </a>
            <a class="navbar-item" href="https://bootstap.github.io/">
              BootsTAP
            </a>
            <a class="navbar-item" href="https://tapvid3d.github.io/">
              TAPVid-3D
            </a>
            <a class="navbar-item" href="https://tap-next.github.io/">
              TAPNext
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-2 publication-title">TAP-Vid: A Benchmark for Tracking Any Point in a Video</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=Jvi_XPAAAAAJ">Carl Doersch</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.robots.ox.ac.uk/~ankush/">Ankush Gupta</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.ru/citations?user=jM6Y0yAAAAAJ">Larisa Markeeva</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="http://people.csail.mit.edu/recasens/">Adrià Recasens</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=yN7CEicAAAAJ">Lucas Smaira</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="http://people.csail.mit.edu/yusuf/">Yusuf Aytar</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.co.uk/citations?user=IUZ-7_cAAAAJ">João Carreira</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="https://yangyi02.github.io">Yi Yang</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Google DeepMind,</span>
              <span class="author-block"><sup>2</sup>University of Oxford</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/58168e8a92994655d6da3939e7cc0918-Paper-Datasets_and_Benchmarks.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2211.03726" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/google-deepmind/tapnet/tree/main/tapnet/tapvid"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Data & Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="publication-video" style="padding-bottom: 55%">
              <video id="teaser" autoplay controls muted loop playsinline height="100%">
                <source src="https://storage.googleapis.com/dm-tapnet/tap_vid_zoom_v9.mp4" type="video/mp4">
              </video>
            </div>
            <p>
              Visualization of TAP-Vid Dataset with Human Annotated Ground-Truth Point Tracks
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h3 class="title is-3">Abstract</h3>
          <div class="content has-text-justified">
            <p>
              Generic motion understanding from video involves not only tracking objects, but also perceiving how their
              surfaces deform and move. This information is useful to make inferences about 3D shape, physical
              properties and object interactions. While the problem of tracking arbitrary physical points on surfaces
              over longer video clips has received some attention, no dataset or benchmark for evaluation existed, until
              now. In this paper, we first formalize the problem, naming it tracking any point (TAP). We introduce a
              companion benchmark, TAP-Vid, which is composed of both real-world videos with accurate human annotations
              of point tracks, and synthetic videos with perfect ground-truth point tracks. Central to the construction
              of our benchmark is a novel semi-automatic crowdsourced pipeline which uses optical flow estimates to
              compensate for easier, short-term motion like camera shake, allowing annotators to focus on harder
              sections of video. We validate our pipeline on synthetic data and propose a simple end-to-end point
              tracking model TAP-Net, showing that it outperforms all prior methods on our benchmark when trained on
              synthetic data.
            </p>
          </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h3 class="title is-3">Video Summary</h3>
          <a href="https://nips.cc/virtual/2022/poster/55696">
            <img src="static/images/neurips.png" alt="Video Summary">
          </a>
        </div>
      </div>
    </div>


    <div class="container is-max-desktop">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h3 class="title is-3">Annotation Workflow</h3>
          <div class="publication-video" style="padding-bottom: 50%">
            <video id="teaser" autoplay controls muted loop playsinline height="100%">
              <source src="https://storage.googleapis.com/dm-tapnet/annotation_screen_capture.mov" type="video/mp4">
            </video>
          </div>
          <div class="content has-text-justified">
            <p>
              A screen capture showing the typical annotation workflow and usage of the web-interface while annotating
              three point tracks in a brief video. For brevity, we used points where the optical flow based tracker
              worked exceptionally well and no further refinement was required, although this is not the general case.
            </p>
          </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content">

            <h3 class="title is-3">TAP-Vid-DAVIS</h3>
            <div class="container">
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/bike-packing.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/blackswan.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/bmx-trees.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/breakdance.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/camel.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/car-roundabout.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/car-shadow.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/cows.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/dance-twirl.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/davis_ground_truth_v2/dog.mp4"
                      type="video/mp4">
                  </video>
                </div>
              </div>
            </div>

            <h3 class="title is-3">TAP-Vid-Kinetics</h3>
            <div class="container">
              <div class="content has-text-justified">
                <p>
                  This is the <b>most challenging</b> TAP-Vid subset. All videos are <b>realistic, obtained from Youtube</b>.
                  Annotations are carefully monitored, filtered and refined multiple iterations to guarantee the quality.
                  Unfortunately we cannot directly include Kinetics visualizations due to the licensing of these YouTube
                  videos, but they may be visualized using the <a
                    href="https://github.com/google-deepmind/tapnet/tree/main/tapnet/tapvid#downloading-and-processing-tap-vid-kinetics">download scripts</a>.
                </p>
              </div>
            </div>

            <h3 class="title is-3">TAP-Vid-Kubric</h3>
            <div class="container">
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_1.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_2.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_3.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_4.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_5.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_6.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_7.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_8.mp4"
                      type="video/mp4">
                  </video>
                </div>                          
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_9.mp4"
                      type="video/mp4">
                  </video>
                </div>                                                
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/kubric_ground_truth/kubric_10.mp4"
                      type="video/mp4">
                  </video>
                </div>
              </div>
            </div>

            <h3 class="title is-3">TAP-Vid-RGB-Stacking</h3>
            <div class="container">
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/rgb_stacking_ground_truth_v2/input_video_0.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/rgb_stacking_ground_truth_v2/input_video_1.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/rgb_stacking_ground_truth_v2/input_video_2.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/rgb_stacking_ground_truth_v2/input_video_3.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/rgb_stacking_ground_truth_v2/input_video_4.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/rgb_stacking_ground_truth_v2/input_video_5.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/rgb_stacking_ground_truth_v2/input_video_6.mp4"
                      type="video/mp4">
                  </video>
                </div>
                <div class="item">
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src="https://storage.googleapis.com/dm-tapnet/content/rgb_stacking_ground_truth_v2/input_video_7.mp4"
                      type="video/mp4">
                  </video>
                </div>
              </div>
            </div>

          </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content">
            <h3 class="title is-3">Improving Annotation with Flow based Tracker</h3>
            <div class="container">
              <div class="content has-text-justified">
                <p>
                  Annotating videos with high-quality point tracks is a very challenging task. We use an optical flow
                  based point interpolation to aid the human annotators in this task. On the left below are annotations
                  obtained without this tracker, and on the right with the tracker. The tracker results in more
                  spatially consistent tracks, and also speeds up the annotation process by over 40%, aiding and
                  simplifying the annotation effort substantially.
                </p>
              </div>            
              <table style="width: 100%; border-collapse: collapse; border-spacing: 0;">
                <tr>
                  <td style="text-align:center; padding: 10px 0;"><b>Without flow tracker assist</b></td>
                  <td style="text-align:center; padding: 10px 0;"><b>With flow tracker assist</b></td>
                </tr>
                <tr>
                  <td colspan="2" style="padding: 0; text-align: center; padding-bottom: 20px;">
                    <video width="1024" controls autoplay style="display: block; margin: 0 auto;">
                      <source src="https://storage.googleapis.com/dm-tapnet/content/flow_tracker_comparison/blackswan.mp4" type="video/mp4">
                    </video>
                    <p style="margin: 0; padding-top: 10px; width: 100%; text-align: center;">
                      Note the high-frequency jitter for the points on the swan's back and neck that occurs without assistance from optical flow.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td style="text-align:center; padding: 10px 0;"><b>Without flow tracker assist</b></td>
                  <td style="text-align:center; padding: 10px 0;"><b>With flow tracker assist</b></td>
                </tr>
                <tr>
                  <td colspan="2" style="padding: 0; text-align: center; padding-bottom: 20px;">
                    <video width="1024" controls autoplay style="display: block; margin: 0 auto;">
                      <source src="https://storage.googleapis.com/dm-tapnet/content/flow_tracker_comparison/camel.mp4" type="video/mp4">
                    </video>
                    <p style="margin: 0; padding-top: 10px; width: 100%; text-align: center;">
                      Camera shake is particularly problematic, but optical flow compensates very well. It's almost unnoticeable when the flow interpolation is used, but without it, the points jump visibly three-quarters of the way through the video.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td style="text-align:center; padding: 10px 0;"><b>Without flow tracker assist</b></td>
                  <td style="text-align:center; padding: 10px 0;"><b>With flow tracker assist</b></td>
                </tr>
                <tr>
                  <td colspan="2" style="padding: 0; text-align: center; padding-bottom: 20px;">
                    <video width="1024" controls autoplay style="display: block; margin: 0 auto;">
                      <source src="https://storage.googleapis.com/dm-tapnet/content/flow_tracker_comparison/horsejump-high.mp4" type="video/mp4">
                    </video>
                    <p style="margin: 0; padding-top: 10px; width: 100%; text-align: center;">
                      The flow tracker remains consistent even with fast motions, greatly improving the precision of the points on the horse's saddle.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td style="text-align:center; padding: 10px 0;"><b>Without flow tracker assist</b></td>
                  <td style="text-align:center; padding: 10px 0;"><b>With flow tracker assist</b></td>
                </tr>
                <tr>
                  <td colspan="2" style="padding: 0; text-align: center; padding-bottom: 20px;">
                    <video width="1024" controls autoplay style="display: block; margin: 0 auto;">
                      <source src="https://storage.googleapis.com/dm-tapnet/content/flow_tracker_comparison/india.mp4" type="video/mp4">
                    </video>
                    <p style="margin: 0; padding-top: 10px; width: 100%; text-align: center;">
                      Again the flow tracker is useful in compensating for camera motion and zoom.
                    </p>
                  </td>
                </tr>
              </table>
              
            </div>
          </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h3 class="title is-3">Licensing</h3>
          <p>
            The annotations of TAP-Vid, as well as the RGB-Stacking videos, are released under a <a
              href="https://creativecommons.org/licenses/by/4.0/">Creative Commons BY
              license</a>. The original source videos of DAVIS come from the val set, and are also licensed under
            creative
            commons licenses per their creators; see the <a href="https://davischallenge.org/davis2017/code.html">DAVIS
              dataset</a> for details. Kinetics videos are publicly
            available on YouTube, but subject to their own individual licenses. See the <a
              href="https://github.com/cvdfoundation/kinetics-dataset">Kinetics dataset webpage</a> for
            details.
          </p>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h3 class="title is-3">Related Links</h3>
          <div class="content has-text-justified">
            <p>
              <a href="https://particle-video-revisited.github.io/">Particle Video Revisited: Tracking Through
                Occlusions Using Point Trajectories</a> propose Persistent Independent Particles (PIPs), a new particle
              video method that tracks any pixel over time.
            </p>
            <p>
              <a href="https://github.com/google-research/kubric">Kubric: A scalable dataset generator</a> is a data generation pipeline for creating semi-realistic synthetic multi-object videos with rich annotations such as instance segmentation masks, depth maps, and optical flow.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://arxiv.org/abs/2211.03726">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/deepmind/tapnet" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0
                International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/tapvid/tapvid.github.io">source
                code</a> of this website, which itelf is a fork of <a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. We just ask that you link back to this
              page in the footer.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
